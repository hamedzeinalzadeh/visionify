{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3de5913b-5e2e-44f9-9b87-795bf78b43f4",
   "metadata": {},
   "source": [
    "# Multi-Object Tracking Project\n",
    "Each cell represents a method with different building blocks. You can run them seperately (like different `.py` files). \n",
    "> **Consideration:**\n",
    "> \n",
    "> It is better to shutdown other kernels if you are a notebook user, and restart the kernel.\n",
    "## Goal: \n",
    "There are circle-shaped markers on a single device. In a stereo setup, we are looking for the coordinations of these markers. Then, by grabing the coordinates with an approximately identican timing, calculate the position of that object in a 3D space.\n",
    "\n",
    "#### #TODO:\n",
    "- .py version with modularization and be capable of parsing parameters in terminal\n",
    "- There is another options: choose specific trackers for every single object choosen.\n",
    "- this is for oop code for multiobject tracking. check this for more development in the future codes.\n",
    "https://github.com/opencv/opencv-python/issues/695\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* [APIs with Manualy Selection in First Frame](#api_with_manualy_selection)\n",
    "* [APIs with Automaticaly Selection in First Frame Hough Circle Transform](#api_with_automaticaly_detection_hough)\n",
    "* * [APIs with Automaticaly Selection in First Frame Find ](#api_with_automaticaly_detection_hough) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01d3636-9fd1-42fa-b83a-705cbad592e8",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"api_with_manualy_selection\"></a>\n",
    "\n",
    "---\n",
    "\n",
    "### APIs with Manualy Selection in First Frame\n",
    "#### **Running Process**:\n",
    "\n",
    "First of all the firt frame of the first camera is appeared, then ROIs can be selected manualy(after each selection, press `Enter` or `Space`). Then, press `Esc` to pass this process on the second frame of the second camera. \n",
    "After pressing `Esc` againg, 2 windows are shown up with bounding boxes tracking selected objects.\n",
    "\n",
    ">**NOTE:**\n",
    ">\n",
    "> It is important to select the objects in the same order between the first frames in first camera and second camera.\n",
    "\n",
    "\n",
    "#### **Output format**: \n",
    "There are two lists named: `bboxes_centers1` and `bboxes_centers2` for center of objects in first camera and second camera respectively.\n",
    "\n",
    "In each list, every single elements has this structure --> `(x_of_center, y_of_center, time_stamp, index_of_object)`\n",
    "\n",
    "So, It is possible to distinguish the corresponding coordinates of every single object between the two lists(two cameras) by comparing `time_stamp` and `index_of_object`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9954b84-2769-4e17-8fdd-daa366ea1626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracker APIs available: \n",
      "Enter 0 for BOOSTING: \n",
      "Enter 1 for MIL: \n",
      "Enter 2 for KCF: \n",
      "Enter 3 for TLD: \n",
      "Enter 4 for MEDIANFLOW: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please select your tracker:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish the selection process by pressing ESC button!\n",
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n",
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n",
      "Finish the selection process by pressing ESC button!\n",
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n",
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@4419.084] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (2401) handleMessage OpenCV | GStreamer warning: Embedded video playback halted; module source reported: Could not read from resource.\n",
      "[ WARN:0@4419.084] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (1356) open OpenCV | GStreamer warning: unable to start pipeline\n",
      "[ WARN:0@4419.084] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "[ WARN:0@4419.384] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (2401) handleMessage OpenCV | GStreamer warning: Embedded video playback halted; module source reported: Could not read from resource.\n",
      "[ WARN:0@4419.385] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (1356) open OpenCV | GStreamer warning: unable to start pipeline\n",
      "[ WARN:0@4419.385] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "# Function for choosing number of different types of tracker APIs\n",
    "def ask_for_tracker():\n",
    "    # TODO: Add GOTURN, MOSSE, CSRT\n",
    "    print(\"Tracker APIs available: \")\n",
    "    print(\"Enter 0 for BOOSTING: \")\n",
    "    print(\"Enter 1 for MIL: \")\n",
    "    print(\"Enter 2 for KCF: \")\n",
    "    print(\"Enter 3 for TLD: \")\n",
    "    print(\"Enter 4 for MEDIANFLOW: \")\n",
    "    choice = input(\"Please select your tracker: \")\n",
    "    \n",
    "    return choice\n",
    "\n",
    "\n",
    "# Function for setting different types of tracker APIs\n",
    "def create_tracker(choice):\n",
    "    if choice == '0':\n",
    "        tracker = cv2.legacy.TrackerBoosting_create()\n",
    "    if choice == '1':\n",
    "        tracker = cv2.TrackerMIL_create()\n",
    "    if choice == '2':\n",
    "        tracker = cv2.legacy.TrackerKCF_create()\n",
    "    if choice == '3':\n",
    "        tracker = cv2.legacy.TrackerTLD_create()\n",
    "    if choice == '4':\n",
    "        # tracker = cv2.TrackerMedianFlow_create()\n",
    "        tracker = cv2.legacy.TrackerMedianFlow_create()\n",
    "    \n",
    "    return tracker\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ask for Tracker \n",
    "tracker_number = ask_for_tracker()\n",
    "#tracker_name = str(tracker).split()[1]\n",
    "\n",
    "\n",
    "# Create a MultiTracker object\n",
    "multi_tracker1 = cv2.legacy.MultiTracker_create()\n",
    "multi_tracker2 = cv2.legacy.MultiTracker_create()\n",
    "#multi_tracker = []\n",
    "\n",
    "# Read video\n",
    "# First Camera\n",
    "cap1 = cv2.VideoCapture()\n",
    "cap1.open(\"/dev/v4l/by-path/pci-0000:00:14.0-usb-0:5:1.0-video-index0\")\n",
    "# cap1 = cv2.VideoCapture(cv2.CAP_V4L2 + 0)\n",
    "\n",
    "# Read video\n",
    "# Second Camera\n",
    "cap2 = cv2.VideoCapture()\n",
    "cap2.open(\"/dev/v4l/by-path/pci-0000:00:14.0-usb-0:6:1.0-video-index0\")\n",
    "# cap2 = cv2.VideoCapture(cv2.CAP_V4L2 + 2)\n",
    "\n",
    "\n",
    "# Read first frame.\n",
    "ret1, frame1 = cap1.read()\n",
    "\n",
    "# Read first frame.\n",
    "ret2, frame2 = cap2.read()\n",
    "\n",
    "# Select multiple ROIs in the first frame for the first camera\n",
    "# bboxes elements' structure --> (x, y, w, h)\n",
    "bboxes1 = cv2.selectROIs(\"Select ROIs\", frame1)\n",
    "cv2.destroyWindow(\"Select ROIs\")\n",
    "\n",
    "# Select multiple ROIs in the first frame for the second camera\n",
    "# bboxes elements' structure --> (x, y, w, h)\n",
    "bboxes2 = cv2.selectROIs(\"Select ROIs\", frame2)\n",
    "cv2.destroyWindow(\"Select ROIs\")\n",
    "\n",
    "\n",
    "# Initialize trackers for selected ROIs(first camera)\n",
    "# It is essential to create new tracker objects in each iteration.\n",
    "for bbox in bboxes1:\n",
    "    tracker = create_tracker(tracker_number)\n",
    "    multi_tracker1.add(tracker, frame1, tuple(bbox))\n",
    "\n",
    "# Initialize trackers for selected ROIs(second camera)\n",
    "# It is essential to create new tracker objects in each iteration.\n",
    "for bbox in bboxes2:\n",
    "    tracker = create_tracker(tracker_number)\n",
    "    multi_tracker2.add(tracker, frame2, tuple(bbox))\n",
    "\n",
    "# Initialize a list for getting center of objects\n",
    "bboxes_centers1 = []\n",
    "bboxes_centers2 = []\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    # Read a new frame\n",
    "    ret1, frame1 = cap1.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "\n",
    "    # Update the tracker with the current frame\n",
    "    success1, bboxes1 = multi_tracker1.update(frame1)\n",
    "    time_stamp1 = time.time() - start_time\n",
    "    success2, bboxes2 = multi_tracker2.update(frame2)\n",
    "    time_stamp2 = time.time() - start_time\n",
    "    \n",
    "    # first camera\n",
    "    if success1:\n",
    "        # Draw bounding boxes\n",
    "        # Roi variable is a tuple of 4 floats, we need them as int\n",
    "        for index in range(len(bboxes1)):\n",
    "            (x1, y1, w1, h1) = [int(i) for i in bboxes1[index]]\n",
    "            cv2.rectangle(frame1, (x1, y1), (x1 + w1, y1 + h1), (0, 255, 0), 2)\n",
    "            bboxes_centers1.append((x1+(w1 / 2), y1+(h1 / 2), time_stamp1, index))\n",
    "            \n",
    "    else:\n",
    "        # Tracking failure\n",
    "        cv2.putText(frame1, \"Failure to Detect Tracking!\", (100,200), cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255),3)\n",
    "\n",
    "    \n",
    "    # second camera    \n",
    "    if success2:\n",
    "        # Draw bounding boxes\n",
    "        # Roi variable is a tuple of 4 floats, we need them as int\n",
    "        for index in range(len(bboxes2)):\n",
    "            (x2, y2, w2, h2) = [int(i) for i in bboxes2[index]]\n",
    "            cv2.rectangle(frame2, (x2, y2), (x2 + w2, y2 + h2), (0, 255, 0), 2)\n",
    "            bboxes_centers2.append((x2+(w2 / 2), y2+(h2 / 2), time_stamp2, index))\n",
    "            \n",
    "    else:\n",
    "        # Tracking failure\n",
    "        cv2.putText(frame2, \"Failure to Detect Tracking!\", (100,200), cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255),3)\n",
    "\n",
    "\n",
    "    \n",
    "    # Display result\n",
    "    tracker_name = str(tracker).split()[1]\n",
    "    cv2.imshow(tracker_name + 'camera 1', frame1)\n",
    "    cv2.imshow(tracker_name + 'camera 2', frame2)\n",
    "    \n",
    "    \n",
    "    # Exit if ESC pressed\n",
    "    if (cv2.waitKey(30) & 0xff) == 27: \n",
    "        break\n",
    "\n",
    "cap1.release()\n",
    "cap2.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681951f9-3fef-401f-b47c-f5a779c36360",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"api_with_automaticaly_detection_hough\"></a>\n",
    "\n",
    "---\n",
    "\n",
    "### APIs with Automaticaly Selection in First Frame Hough Circle Transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d1834a5-ab9e-42ff-9773-09f7b24ce321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracker APIs available: \n",
      "Enter 0 for BOOSTING: \n",
      "Enter 1 for MIL: \n",
      "Enter 2 for KCF: \n",
      "Enter 3 for TLD: \n",
      "Enter 4 for MEDIANFLOW: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please select your tracker:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1.722] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (2401) handleMessage OpenCV | GStreamer warning: Embedded video playback halted; module source reported: Could not read from resource.\n",
      "[ WARN:0@1.722] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (1356) open OpenCV | GStreamer warning: unable to start pipeline\n",
      "[ WARN:0@1.722] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "\n",
      "(python:12316): GStreamer-CRITICAL **: 04:15:47.910: gst_element_make_from_uri: assertion 'gst_uri_is_valid (uri)' failed\n",
      "[ WARN:0@1.902] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (1127) open OpenCV | GStreamer warning: Error opening bin: no source element for URI \"/dev/v4l/by-path/pci-0000:00:14.0-usb-0:6:1.0-video-index0\"\n",
      "[ WARN:0@1.902] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n",
      "libGL error: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "libGL error: failed to load driver: iris\n",
      "libGL error: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "libGL error: failed to load driver: swrast\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /croot/opencv-suite_1676452025216/work/modules/highgui/src/window.cpp:967: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 73\u001b[0m\n\u001b[1;32m     69\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyWindow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelect ROIs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Select multiple ROIs in the first frame for the second camera\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# bboxes elements' structure --> (x, y, w, h)\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m bboxes2 \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselectROIs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSelect ROIs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyWindow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelect ROIs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Initialize trackers for selected ROIs(first camera)\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# It is essential to create new tracker objects in each iteration.\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /croot/opencv-suite_1676452025216/work/modules/highgui/src/window.cpp:967: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "# Function for choosing number of different types of tracker APIs\n",
    "def ask_for_tracker():\n",
    "    # TODO: Add GOTURN, MOSSE, CSRT\n",
    "    print(\"Tracker APIs available: \")\n",
    "    print(\"Enter 0 for BOOSTING: \")\n",
    "    print(\"Enter 1 for MIL: \")\n",
    "    print(\"Enter 2 for KCF: \")\n",
    "    print(\"Enter 3 for TLD: \")\n",
    "    print(\"Enter 4 for MEDIANFLOW: \")\n",
    "    choice = input(\"Please select your tracker: \")\n",
    "    \n",
    "    return choice\n",
    "\n",
    "\n",
    "# Function for setting different types of tracker APIs\n",
    "def create_tracker(choice):\n",
    "    if choice == '0':\n",
    "        tracker = cv2.legacy.TrackerBoosting_create()\n",
    "    if choice == '1':\n",
    "        tracker = cv2.TrackerMIL_create()\n",
    "    if choice == '2':\n",
    "        tracker = cv2.legacy.TrackerKCF_create()\n",
    "    if choice == '3':\n",
    "        tracker = cv2.legacy.TrackerTLD_create()\n",
    "    if choice == '4':\n",
    "        # tracker = cv2.TrackerMedianFlow_create()\n",
    "        tracker = cv2.legacy.TrackerMedianFlow_create()\n",
    "    \n",
    "    return tracker\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ask for Tracker \n",
    "tracker_number = ask_for_tracker()\n",
    "#tracker_name = str(tracker).split()[1]\n",
    "\n",
    "\n",
    "# Create a MultiTracker object\n",
    "multi_tracker1 = cv2.legacy.MultiTracker_create()\n",
    "multi_tracker2 = cv2.legacy.MultiTracker_create()\n",
    "#multi_tracker = []\n",
    "\n",
    "# Read video\n",
    "# First Camera\n",
    "cap1 = cv2.VideoCapture()\n",
    "cap1.open(\"/dev/v4l/by-path/pci-0000:00:14.0-usb-0:5:1.0-video-index0\")\n",
    "# cap1 = cv2.VideoCapture(cv2.CAP_V4L2 + 0)\n",
    "\n",
    "# Read video\n",
    "# Second Camera\n",
    "cap2 = cv2.VideoCapture()\n",
    "cap2.open(\"/dev/v4l/by-path/pci-0000:00:14.0-usb-0:6:1.0-video-index0\")\n",
    "# cap2 = cv2.VideoCapture(cv2.CAP_V4L2 + 2)\n",
    "\n",
    "\n",
    "# Read first frame.\n",
    "ret1, frame1 = cap1.read()\n",
    "\n",
    "# Read first frame.\n",
    "ret2, frame2 = cap2.read()\n",
    "\n",
    "# Select multiple ROIs in the first frame for the first camera\n",
    "# bboxes elements' structure --> (x, y, w, h)\n",
    "bboxes1 = cv2.selectROIs(\"Select ROIs\", frame1)\n",
    "cv2.destroyWindow(\"Select ROIs\")\n",
    "\n",
    "# Select multiple ROIs in the first frame for the second camera\n",
    "# bboxes elements' structure --> (x, y, w, h)\n",
    "bboxes2 = cv2.selectROIs(\"Select ROIs\", frame2)\n",
    "cv2.destroyWindow(\"Select ROIs\")\n",
    "\n",
    "\n",
    "# Initialize trackers for selected ROIs(first camera)\n",
    "# It is essential to create new tracker objects in each iteration.\n",
    "for bbox in bboxes1:\n",
    "    tracker = create_tracker(tracker_number)\n",
    "    multi_tracker1.add(tracker, frame1, tuple(bbox))\n",
    "\n",
    "# Initialize trackers for selected ROIs(second camera)\n",
    "# It is essential to create new tracker objects in each iteration.\n",
    "for bbox in bboxes2:\n",
    "    tracker = create_tracker(tracker_number)\n",
    "    multi_tracker2.add(tracker, frame2, tuple(bbox))\n",
    "\n",
    "# Initialize a list for getting center of objects\n",
    "bboxes_centers1 = []\n",
    "bboxes_centers2 = []\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    # Read a new frame\n",
    "    ret1, frame1 = cap1.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "\n",
    "    # Update the tracker with the current frame\n",
    "    success1, bboxes1 = multi_tracker1.update(frame1)\n",
    "    time_stamp1 = time.time() - start_time\n",
    "    success2, bboxes2 = multi_tracker2.update(frame2)\n",
    "    time_stamp2 = time.time() - start_time\n",
    "    \n",
    "    # first camera\n",
    "    if success1:\n",
    "        # Draw bounding boxes\n",
    "        # Roi variable is a tuple of 4 floats, we need them as int\n",
    "        for index in range(len(bboxes1)):\n",
    "            (x1, y1, w1, h1) = [int(i) for i in bboxes1[index]]\n",
    "            cv2.rectangle(frame1, (x1, y1), (x1 + w1, y1 + h1), (0, 255, 0), 2)\n",
    "            bboxes_centers1.append((x1+(w1 / 2), y1+(h1 / 2), time_stamp1, index))\n",
    "            \n",
    "    else:\n",
    "        # Tracking failure\n",
    "        cv2.putText(frame1, \"Failure to Detect Tracking!\", (100,200), cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255),3)\n",
    "\n",
    "    \n",
    "    # second camera    \n",
    "    if success2:\n",
    "        # Draw bounding boxes\n",
    "        # Roi variable is a tuple of 4 floats, we need them as int\n",
    "        for index in range(len(bboxes2)):\n",
    "            (x2, y2, w2, h2) = [int(i) for i in bboxes2[index]]\n",
    "            cv2.rectangle(frame2, (x2, y2), (x2 + w2, y2 + h2), (0, 255, 0), 2)\n",
    "            bboxes_centers2.append((x2+(w2 / 2), y2+(h2 / 2), time_stamp2, index))\n",
    "            \n",
    "    else:\n",
    "        # Tracking failure\n",
    "        cv2.putText(frame2, \"Failure to Detect Tracking!\", (100,200), cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255),3)\n",
    "\n",
    "\n",
    "    \n",
    "    # Display result\n",
    "    tracker_name = str(tracker).split()[1]\n",
    "    cv2.imshow(tracker_name + 'camera 1', frame1)\n",
    "    cv2.imshow(tracker_name + 'camera 2', frame2)\n",
    "    \n",
    "    # Exit if ESC pressed\n",
    "    if (cv2.waitKey(30) & 0xff) == 27: \n",
    "        break\n",
    "\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
